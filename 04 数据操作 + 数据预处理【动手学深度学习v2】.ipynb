{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[04 数据操作 + 数据预处理【动手学深度学习v2】](https://www.bilibili.com/video/BV1CV411Y7i4?spm_id_from=333.999.0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x里面标量的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[ 0,  1,  2,  3],\n",
    "        [ 4,  5,  6,  7],\n",
    "        [ 8,  9, 10, 11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.,  4.,  6., 10.]),\n",
       " tensor([-1.,  0.,  2.,  6.]),\n",
       " tensor([ 2.,  4.,  8., 16.]),\n",
       " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
       " tensor([ 1.,  4., 16., 64.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0,2,4,8])\n",
    "y = torch.tensor([2,2,2,2])\n",
    "x+y,x-y,x*y,x/y,x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(12).reshape(3,4)\n",
    "y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,   3],\n",
       "        [  4,   5,   6,   7],\n",
       "        [  8,   9,  10,  11],\n",
       "        [  0,   1,   4,   9],\n",
       "        [ 16,  25,  36,  49],\n",
       "        [ 64,  81, 100, 121]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x,y),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,   3,   0,   1,   4,   9],\n",
       "        [  4,   5,   6,   7,  16,  25,  36,  49],\n",
       "        [  8,   9,  10,  11,  64,  81, 100, 121]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x,y),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[numpy广播机制](https://www.runoob.com/numpy/numpy-broadcast.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape(3,1)\n",
    "b = torch.arange(2).reshape(1,2)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [0, 1],\n",
       "        [0, 2]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "减少内存开销"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(x)\n",
    "x +=y\n",
    "id(x) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与numpy之间的相互转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   2,   6,  12],\n",
       "       [ 20,  30,  42,  56],\n",
       "       [ 72,  90, 110, 132]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = x.numpy()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   2,   6,  12],\n",
       "        [ 20,  30,  42,  56],\n",
       "        [ 72,  90, 110, 132]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5000]), 3.5, 3.5, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([3.5])\n",
    "a,a.item(),float(a),int(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算机中矩阵的乘法定义为哈达吗积，即直接进行元素相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     2,    24,   108],\n",
       "        [  320,   750,  1512,  2744],\n",
       "        [ 4608,  7290, 11000, 15972]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数学中的乘积定义如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  134,   854,  2214],\n",
       "        [  702,  5326, 14686],\n",
       "        [ 1718, 13830, 38870]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x@y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  2,   4,   8,  14],\n",
       "         [ 22,  32,  44,  58],\n",
       "         [ 74,  92, 112, 134]]),\n",
       " tensor([[  0,   4,  12,  24],\n",
       "         [ 40,  60,  84, 112],\n",
       "         [144, 180, 220, 264]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "a+x,a*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19]],\n",
       "\n",
       "        [[20, 21, 22, 23],\n",
       "         [24, 25, 26, 27],\n",
       "         [28, 29, 30, 31],\n",
       "         [32, 33, 34, 35],\n",
       "         [36, 37, 38, 39]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20*2).reshape(2,5,4)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 个人理解，n维数组是一个从外向内包裹的一个过程，比如一个数组shape为[2,3,4],那么依次对应axis=0,1,2三种情况\n",
    "- 但是数组是从外向内包裹的，所以axis=0 也是就2是最外面为2，也就是2个3行4列矩阵叠加形成\n",
    "- 具体的包裹方式：第一层最简单，就是数组，这是最里层，然后是外层，对应的axis的最大值，也就是按行叠加，此时形成的就是矩阵，对应着axis的次大值。\n",
    "- A为2,5,4，矩阵，那么就意味着A的最外围是2\n",
    "- A.sum(dim=0)就意味着最外围求和，形成的是，相当于两个5行4列的矩阵相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20, 22, 24, 26],\n",
       "        [28, 30, 32, 34],\n",
       "        [36, 38, 40, 42],\n",
       "        [44, 46, 48, 50],\n",
       "        [52, 54, 56, 58]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 40,  45,  50,  55],\n",
       "        [140, 145, 150, 155]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 同理，A.sum(dim=1),对应的是次大层，此时将按行求和\n",
    "# 按行求和后，axis=2对应的4依旧为最里层，此时每行依旧为4\n",
    "# 但是axis=0 对应的最外层将变列值，此时将变成2行，4列矩阵\n",
    "A.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  6,  22,  38,  54,  70],\n",
       "        [ 86, 102, 118, 134, 150]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axis = 2 的情况就是最里层也就是数组行的求和\n",
    "# 此时axis=1也就是5将变为最里层，也就是变成长度为5的数组\n",
    "A.sum(dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[20, 22, 24, 26],\n",
       "          [28, 30, 32, 34],\n",
       "          [36, 38, 40, 42],\n",
       "          [44, 46, 48, 50],\n",
       "          [52, 54, 56, 58]]]),\n",
       " tensor([[20, 22, 24, 26],\n",
       "         [28, 30, 32, 34],\n",
       "         [36, 38, 40, 42],\n",
       "         [44, 46, 48, 50],\n",
       "         [52, 54, 56, 58]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算时候保持数组维数不变\n",
    "# 此时可以看到数组维数保留\n",
    "# 想要利用广播机制，可以采用此方法\n",
    "suma = A.sum(dim=0,keepdim=True)\n",
    "sumb = A.sum(dim=0)\n",
    "suma,sumb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(8.), tensor(8.))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵点积是元素乘积求和\n",
    "x = torch.ones(4,dtype=torch.float32)\n",
    "y = x+1\n",
    "torch.dot(x,y),torch.sum(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19]]),\n",
       " tensor([1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20).reshape(5,4)\n",
    "A,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4290, -0.2537,  0.3937],\n",
       "         [ 0.3894,  1.2570, -0.8814]]),\n",
       " tensor([-0.2025,  1.5324, -1.0054]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.randn(2,3)\n",
    "b=torch.randn(3)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8714,  2.7334])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mv为向量和矩阵的乘积\n",
    "torch.mv(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mm 为矩阵与矩阵的乘积\n",
    "a = torch.arange(20).reshape(5,4)\n",
    "b = torch.arange(12).reshape(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 42,  48,  54],\n",
       "        [114, 136, 158],\n",
       "        [186, 224, 262],\n",
       "        [258, 312, 366],\n",
       "        [330, 400, 470]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n范数\n",
    "- 数组的i范数很好理解，就是元素的i次方求和再取i次方根\n",
    "- 矩阵的i范数，就是矩阵所有元素i次方求和再取i次方根"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3500, 0.1935, 0.9225, 0.8310],\n",
       "        [0.2691, 0.9266, 0.9021, 0.2724],\n",
       "        [0.0763, 0.0644, 0.5296, 0.5885],\n",
       "        [0.6984, 0.9065, 0.2435, 0.9297],\n",
       "        [0.6634, 0.6164, 0.7250, 0.8209]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(20).reshape(5,4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9001)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算矩阵的2范数\n",
    "torch.norm(a)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
